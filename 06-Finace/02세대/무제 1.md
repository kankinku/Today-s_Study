말투는 저렴해도 이글의 가격은 안 저렴하다. GPU 37분 3초 조진거다. 이정도면 읽을 가치는 충분히 한다.

[

![이미지](https://pbs.twimg.com/media/G_tgE33aUAAn2VS?format=png&name=small)





](https://x.com/endurance9999/article/2016314426471940152/media/2016310895010533376)

그럼 시작한다.

“TB는 싸졌는데, MW가 터진다” 2026년 1월 28일 미국 버지니아, 빅테크 AI 데이터센터 상황실

벽에는 빨간 글씨 하나: “POWER CAP: 80MW” 테이블 위엔 GPU 랙 배치도보다 “전력 예산표”가 더 크게 깔려 있다.

🟢 운영팀 B가 입을 연다. “GPU는 더 꽂을 수 있어요.”

🔴 전력팀 C가 비웃듯 끊는다. “꽂아. 대신 전기도 네가 들고 와. Bring your own energy. Behind-the-meter로.”

잠깐 정적.

🟣 스토리지 아키텍트 D가 화이트보드에 계단을 그린다. “그리고 전력 문제, 이제 GPU만의 얘기 아니에요.” “전기가 ‘저장장치’로 내려오고 있습니다.”

> HBM → DRAM → SSD → HDD

🟡 구매팀 E가 밝은 표정으로 박수 친다. “좋네. 아래로 내려가면 싸잖아. TB당 가격도, TB당 전기도!”

🟣 D가 펜으로 ‘TB’에 X표를 친다. “그게 오늘의 함정입니다.” “스토리지 전기는 딱 두 개예요.”

첫째: “들고 있는 전기” (보관 전기) 둘째: “꺼내오는 전기” (이동 전기)

🟣 D가 냉정하게 한 줄로 박는다. “HDD는 ‘보관’은 천재, ‘꺼내오기’는 바보예요.”

🔴 C가 묻는다. “그래서 내려가면 전기는 줄어? 늘어?”

🟣 D가 손가락으로 계단을 ‘툭툭’ 찍는다. “콜드 데이터(거의 안 꺼내는 것)면 줄어요. 이건 진짜 절약.” “근데 웜/핫 데이터(자주 꺼내는 것)까지 HDD로 내리면… 전기는 ‘폭발’할 수 있어요.”

🟡 E가 반발한다. “아니 HDD가 더 전기 적게 먹는다며요!”

🟣 D가 한 마디로 끝낸다. “TB당 전기는 적죠.” “하지만 GB/s당 전기는 비싸요.” “같은 속도를 만들려면 HDD를 ‘수백 개’ 깔아야 하고, 그 순간부터 랙, 팬, 네트워크, 컨트롤러 전력이 다 같이 따라옵니다.”

🟢 B가 스크린을 띄운다. ‘RAG/검색 트래픽 증가 = 작은 랜덤 읽기 폭증’

🟢 B가 말한다. “AI는 요즘 ‘창고에서 바늘 찾기’를 시킵니다.” “그 바늘찾기를 HDD로 하면… 전기랑 지연시간이 같이 터져요.”

🟣 D가 마지막 변수를 던진다. “그리고 청크(저장 단위) 커지는 것도 양날이에요.” “청크가 커져서 ‘쓸데없는 바이트’까지 퍼오면 전기 증가.” “청크를 키워서 ‘랜덤을 줄이고 순차로’ 만들면 전기 감소.” “즉, 청크는 ‘최적화’면 약, ‘대충’이면 독.”

> 잠깐 침묵.

🔴 C가 결론을 한 문장으로 자른다. “정리.” “데이터가 아래로 내려가면 ‘보관 전기’는 줄어든다.” “하지만 AI가 데이터를 더 자주 꺼내 쓰는 구조면 ‘이동 전기’ 때문에 SSD/메모리 쪽이 다시 커진다.”

투자자 번역(핵심만)

- HBM: 핫 티어 필수. 전력 제약 심할수록 “효율 좋은 고대역”이 더 비싸진다.
    
- DRAM: 필요하지만 전기 비싸서 무한정 못 늘린다(캐시/압축/오프로딩이 같이 간다).
    
- SSD: 실시간 AI(RAG/검색/체크포인트)가 커질수록 가장 직접적인 수혜 구간.
    
- HDD: 콜드/아카이브는 계속 필요. 하지만 “자주 꺼내는 AI”가 때리면 역할이 급격히 제한된다.