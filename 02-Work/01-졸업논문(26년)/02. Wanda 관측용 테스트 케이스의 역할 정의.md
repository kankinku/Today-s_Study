## 1.1 목적

관측용 테스트 케이스의 목적은 성능 측정이 아니라:

- 특정 도메인(코딩/디버깅/보안 등)에 대해
    
- 베이스 모델 내부에서 **실제로 활성화되는 경로(회로)**를
    
- 안정적으로 재현 가능한 방식으로 켜서
    
- **중요도 스코어링이 일관되게 나오게 하는 것**
    

즉, “평가 데이터셋”이 아니라 **프로파일링 워크로드**에 가깝다.

---

# 2. 캘리브레이션 세트 설계 원칙 6가지

## 2.1 커버리지보다 “대표성”

- 수천 개가 필요하지 않음
    
- 도메인의 핵심 사고 패턴을 **짧고 강하게** 자극하는 게 중요
    

## 2.2 난이도는 “중간 이상”이 유리

- 너무 쉬운 문제는 공통 회로(언어 일반 능력)만 켜짐
    
- 너무 어려우면 노이즈(헛추론)로 활성 패턴이 흐려질 수 있음
    
- “전문 회로가 켜지는 난이도”를 목표로 잡기
    

## 2.3 형식 다양성(프롬프트 템플릿 다양화)

같은 내용이라도 요청 형태를 바꾸면 다른 경로가 켜질 수 있음

- 구현 요청
    
- 리팩터링 요청
    
- 코드 리뷰 요청
    
- 테스트 작성 요청
    
- 취약점 분석 요청
    

## 2.4 멀티스텝 사고를 강제

Wanda 관측은 “실제로 쓰인 연산 기여도”를 보고 싶기 때문에,

- 단계적 추론
    
- 계획 수립
    
- 검증  
    을 강제하는 케이스가 유리
    

## 2.5 출력 제약을 걸어 회로를 명확히

- “정확히 3단계로”
    
- “시간복잡도 포함”
    
- “테스트 케이스 5개 포함”  
    같은 제약은 단순 언어 생성이 아닌 **구조화된 계산**을 유도
    

## 2.6 중복 제거(활성 패턴의 편향 방지)

똑같은 유형만 반복하면 특정 패턴만 과대표집됨  
→ “전문성”이 아니라 “특정 프롬프트 스타일”을 추출할 위험

---

# 3. 도메인별 관측용 테스트 케이스 구성안

아래는 “Coder / Debugger / Security” 같은 Fragment를 만들 때,  
각각 어떤 케이스를 넣으면 전문 회로가 잘 켜지는지에 대한 실전 구조야.

## 3.1 Coder Fragment (구현/설계 중심)

포함할 유형:

- 자료구조/알고리즘 구현 (중간 난이도)
    
- API 설계(입출력 명세 + 예외)
    
- 리팩터링(함수 분리, 의존성 정리)
    
- 테스트 코드 생성(pytest, jest)
    
- 성능 최적화(시간/메모리 제약 포함)
    

권장 구성:

- 짧은 구현 30%
    
- 리팩터링/설계 40%
    
- 테스트/성능 30%
    

## 3.2 Debugger Fragment (원인 추적/수정 중심)

포함할 유형:

- 에러 로그 기반 원인 분석
    
- 경계값/예외 케이스 수정
    
- 타입/비동기/상태 관련 버그
    
- 재현 코드 작성 + 수정 패치 제안
    
- “왜 발생했는지” 설명 포함
    

권장 구성:

- 로그 기반 40%
    
- 재현/테스트 30%
    
- 패치/리뷰 30%
    

## 3.3 Security Fragment (취약점/위협 모델 중심)

포함할 유형:

- 입력 검증 누락, 인젝션(XSS/SQLi) 분석
    
- 인증/인가(세션, JWT) 설계 검토
    
- 안전한 암호화/키관리 실수 탐지
    
- 의존성 취약점 대응(업데이트/완화)
    
- 위협 모델링(STRIDE 류)
    

권장 구성:

- 코드 스니펫 취약점 분석 50%
    
- 설계 검토/위협 모델 30%
    
- 대응/완화책 제시 20%
    

---

# 4. “테스트 케이스”를 어떻게 만들면 빠르고 안정적인가

## 4.1 현실적인 제작 방법 3가지

### 방법 A: 템플릿 + 변수 치환 (권장)

- 프롬프트 템플릿 30~50개를 만들고
    
- 언어/프레임워크/난이도/제약조건만 바꿔서 확장
    

장점:

- 편향 통제 쉬움
    
- 재현성 높음
    

### 방법 B: 실제 이슈 로그/PR 기반 샘플링

- 오픈소스 이슈/PR/보안 공지에서 발췌  
    장점:
    
- 실제성 강함  
    단점:
    
- 정제 비용 큼
    

### 방법 C: 기존 벤치마크에서 “관측용으로 재가공”

- HumanEval, MBPP 등에서 일부 추출
    
- 단, 성능평가 목적이 아니라 “회로 활성” 목적에 맞게 프롬프트 형태를 변형
    

---

# 5. 캘리브레이션 세트의 크기 감(현실 기준)

너가 목표로 하는 게 “관측”이라면 대략:

- 최소: 50~100개
    
- 권장: 200~500개
    
- 상한: 1,000개 이상은 비용 대비 이득이 줄어드는 편
    

핵심은 개수보다:

- 템플릿 다양성
    
- 난이도 분포
    
- 도메인 커버리지
    
- 중복 제거  
    

---

# 7. 바로 적용 가능한 ‘결론’

너 말대로 **Wanda 관측을 위한 테스트 케이스는 반드시 필요**하고,  
그 성격은 “평가”가 아니라 “프로파일링 워크로드(회로를 켜는 자극)”다.